{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841c91ba",
   "metadata": {},
   "source": [
    "# NBA — Part 1: Setup & First SQL workflows\n",
    "\n",
    "Goals\n",
    "- Connect your local dataset to a lightweight SQL workflow (SQLite) and run initial aggregations useful for feature engineering.\n",
    "- Produce a repeatable notebook that: creates/opens a DB, ingests CSVs (if present), and runs example SQL queries to build season-level summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02958cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/darshj/NBA-Contract-Predictor/Baseball/NBA-Contract-Predictor/Basketball')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports and display settings\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 160)\n",
    "repo_root = Path.cwd()\n",
    "repo_root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c961c4",
   "metadata": {},
   "source": [
    "## Create or connect to a local SQLite database\n",
    "\n",
    "Place your CSVs in data/raw (e.g. player_stats.csv, salaries.csv). The code below will create data/database.db and load any CSVs it finds into tables named after the CSV (without extension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = repo_root / 'data'\n",
    "raw_dir = data_dir / 'raw'\n",
    "db_path = data_dir / 'database.db'\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "\n",
    "# Ingest CSVs found in data/raw into SQLite (table name = filename without .csv)\n",
    "for csv_file in raw_dir.glob('*.csv'):\n",
    "    table_name = csv_file.stem\n",
    "    print(f'Loading {csv_file} -> table: {table_name}')\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "print('Database ready at:', db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6dc077",
   "metadata": {},
   "source": [
    "## Example: season-level aggregation with SQL\n",
    "\n",
    "Adjust column/table names to match your CSV schema. This example assumes a table `player_stats` with columns: player_id, season, game_id, points, rebounds, assists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e60cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_query = '''\n",
    "SELECT player_id,\n",
    "       season,\n",
    "       COUNT(DISTINCT game_id) AS games,\n",
    "       SUM(points) AS total_points,\n",
    "       SUM(rebounds) AS total_rebounds,\n",
    "       SUM(assists) AS total_assists\n",
    "FROM player_stats\n",
    "GROUP BY player_id, season\n",
    "ORDER BY season DESC\n",
    "LIMIT 100;\n",
    "'''\n",
    "\n",
    "try:\n",
    "    season_df = pd.read_sql_query(example_query, engine)\n",
    "    season_df['pts_per_game'] = season_df['total_points'] / season_df['games']\n",
    "    season_df['reb_per_game'] = season_df['total_rebounds'] / season_df['games']\n",
    "    season_df['ast_per_game'] = season_df['total_assists'] / season_df['games']\n",
    "    season_df.head()\n",
    "except Exception as e:\n",
    "    print('Error running example query — check table/column names:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767b29d0",
   "metadata": {},
   "source": [
    "## Next steps (Part 1 -> Part 2)\n",
    "- Verify and standardize column names in your CSVs (player ids, season format, game ids).\n",
    "- Write SQL joins to combine stats + salary tables and produce your target variable (e.g., season win shares, efficiency, or a salary gap).\n",
    "- Save useful derived tables in the DB (e.g., season_aggregates, player_career_summaries) to speed iteration.\n",
    "- For Part 2: design feature queries (rolling averages, age curves) using window functions or precomputed rolling tables.\n",
    "\n",
    "If you share a sample of your CSV column names I can add tailored SQL queries next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
